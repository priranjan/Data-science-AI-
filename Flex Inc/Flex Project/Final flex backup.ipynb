{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"flex_train_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Benchmark','Hardware Vendor\\t','System','Processor ','Processor Characteristics','Auto Parallelization','Base Pointer Size','Peak Pointer Size','1st Level Cache', '2nd Level Cache', '3rd Level Cache', 'Other Cache', 'Memory', 'Operating System', 'File System', 'Compiler','# Cores', '# Chips ', '# Cores Per Chip ', '# Threads Per Core',  'Processor MHz','Result', 'Baseline']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = dataset.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_feature = ['# Chips ','# Cores Per Chip ', '# Threads Per Core', 'Processor MHz','Result' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[needed_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[[\"Baseline\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is (38502, 5)\n",
      "The shape of y_train is (38502, 1)\n",
      "The shape of X_test is (9626, 5)\n",
      "The shape of y_test is (9626, 1)\n"
     ]
    }
   ],
   "source": [
    "print (\"The shape of X_train is {}\".format(X_train.shape))\n",
    "print (\"The shape of y_train is {}\".format(y_train.shape))\n",
    "print (\"The shape of X_test is {}\".format(X_test.shape))\n",
    "print (\"The shape of y_test is {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.5000025863987123\n"
     ]
    }
   ],
   "source": [
    "print('score',regressor.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########START NEW WITH ENCODING OF AUTO PARALLIZATION ##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"multi_linear_flex.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_feature = ['# Chips ','# Cores Per Chip ', '# Threads Per Core', 'Processor MHz','Result','Auto Parallelization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[needed_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[[\"Baseline\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= dataset.iloc[:,:].values\n",
    "\n",
    "Labelencoder_X = LabelEncoder()\n",
    "X[:,5] = Labelencoder_X.fit_transform(X[:,5])\n",
    "\n",
    "Z = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features=[5])\n",
    "\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = shuffle(X_train,y_train,random_state=1)\n",
    "X_test,y_test = shuffle(X_test,y_test,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is (40908, 7)\n",
      "The shape of y_train is (40908, 1)\n",
      "The shape of X_test is (7220, 7)\n",
      "The shape of y_test is (7220, 1)\n"
     ]
    }
   ],
   "source": [
    "print (\"The shape of X_train is {}\".format(X_train.shape))\n",
    "print (\"The shape of y_train is {}\".format(y_train.shape))\n",
    "print (\"The shape of X_test is {}\".format(X_test.shape))\n",
    "print (\"The shape of y_test is {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7220, 1)\n"
     ]
    }
   ],
   "source": [
    "y_predict = regressor.predict(X_test)\n",
    "print(y_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 1.0\n"
     ]
    }
   ],
   "source": [
    "print('score',regressor.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[ 3.80075089e-14  2.74375957e-14 -1.45474335e-13 -3.75219845e-13\n",
      "  -1.48658082e-17  7.43966086e-16  1.00000000e+00]]\n",
      "Mean squared error: 0.00\n",
      "Variance score: 1.00\n"
     ]
    }
   ],
   "source": [
    "print('Coefficients: \\n', regressor.coef_)\n",
    "print(\"Mean squared error: %.2f\" % np.mean((regressor.predict(X_test) - y_test) ** 2))\n",
    "print('Variance score: %.2f' % regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# without encoding and removing Auto parallisation #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "testa = pd.read_csv(\"testdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_feature_testa = ['# Chips ','# Cores', '# Enabled Threads Per Core', 'Processor MHz','Peak Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa = testa[needed_feature_testa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya = testa[['Base Result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testa, X_testb, y_testa, y_testb = train_test_split(Xa, ya, test_size=0.50, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_testa,y_testa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = reg.predict(X_testb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.7764790525063969\n"
     ]
    }
   ],
   "source": [
    "print('score',reg.score(X_testb,y_testb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[ 3.86746621e+01  1.45214743e+00  5.57448493e+01 -1.11388395e-02\n",
      "   1.70321996e-01]]\n",
      "Mean squared error: 14756.68\n",
      "Variance score: 0.78\n"
     ]
    }
   ],
   "source": [
    "print('Coefficients: \\n', reg.coef_)\n",
    "print(\"Mean squared error: %.2f\" % np.mean((reg.predict(X_testb) - y_testb) ** 2))\n",
    "print('Variance score: %.2f' % reg.score(X_testb, y_testb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Main Dataset -Cross Validation#######################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindataset = pd.read_csv(\"maindataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50069, 7)\n"
     ]
    }
   ],
   "source": [
    "print(maindataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Chips</th>\n",
       "      <th># Cores Per Chip</th>\n",
       "      <th># Threads Per Core</th>\n",
       "      <th>Processor MHz</th>\n",
       "      <th>Result</th>\n",
       "      <th>Baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50068.000000</td>\n",
       "      <td>50068.000000</td>\n",
       "      <td>50068.000000</td>\n",
       "      <td>50068.000000</td>\n",
       "      <td>50068.000000</td>\n",
       "      <td>50068.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.312435</td>\n",
       "      <td>9.330670</td>\n",
       "      <td>1.556923</td>\n",
       "      <td>2512.636175</td>\n",
       "      <td>347.767114</td>\n",
       "      <td>379.773235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.524210</td>\n",
       "      <td>14.337259</td>\n",
       "      <td>0.609031</td>\n",
       "      <td>529.339397</td>\n",
       "      <td>713.069256</td>\n",
       "      <td>980.850190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>47.400000</td>\n",
       "      <td>52.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2900.000000</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>413.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>512.000000</td>\n",
       "      <td>896.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>31400.000000</td>\n",
       "      <td>51500.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           # Chips   # Cores Per Chip   # Threads Per Core  Processor MHz  \\\n",
       "count  50068.000000       50068.000000        50068.000000   50068.000000   \n",
       "mean       2.312435           9.330670            1.556923    2512.636175   \n",
       "std        5.524210          14.337259            0.609031     529.339397   \n",
       "min        1.000000           1.000000            1.000000     296.000000   \n",
       "25%        2.000000           4.000000            1.000000    2100.000000   \n",
       "50%        2.000000           6.000000            2.000000    2400.000000   \n",
       "75%        2.000000          10.000000            2.000000    2900.000000   \n",
       "max      512.000000         896.000000            8.000000    5000.000000   \n",
       "\n",
       "             Result      Baseline  \n",
       "count  50068.000000  50068.000000  \n",
       "mean     347.767114    379.773235  \n",
       "std      713.069256    980.850190  \n",
       "min        0.000000      0.000000  \n",
       "25%       47.400000     52.700000  \n",
       "50%      110.000000    112.000000  \n",
       "75%      393.000000    413.000000  \n",
       "max    31400.000000  51500.000000  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maindataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_feature_testa = ['# Chips ','# Cores Per Chip ', '# Threads Per Core', 'Processor MHz','Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = maindataset[needed_feature_testa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = maindataset[['Baseline']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into ( training , Validation )and testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test, X_Train, y_Test, y_Train = train_test_split(X, y, test_size=0.95, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_Test is (2503, 5)\n",
      "The shape of y_testb is (2503, 1)\n",
      "The shape of X_Train is (47566, 5)\n",
      "The shape of y_Train is (47566, 1)\n"
     ]
    }
   ],
   "source": [
    "print (\"The shape of X_Test is {}\".format(X_Test.shape))\n",
    "print (\"The shape of y_testb is {}\".format(y_Test.shape))\n",
    "print (\"The shape of X_Train is {}\".format(X_Train.shape))\n",
    "print (\"The shape of y_Train is {}\".format(y_Train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the training data to K Fold cross validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_Train # Some features\n",
    "y = y_Train # Some classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47566, 5)\n",
      "(47566, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X.fillna(0)\n",
    " print(X.shape)\n",
    " X.dropna(axis=0, how='any')\n",
    " print(X.shape)\n",
    " np.any(np.isnan(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data from Nan an finite value\n"
     ]
    }
   ],
   "source": [
    "clean_dataset(X)\n",
    "clean_dataset(y)\n",
    "clean_dataset(X_Test)\n",
    "clean_dataset(y_Test)\n",
    "print(\"cleaning data from Nan an finite value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isfinite(X))\n",
    "np.any(np.isnan(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using one type of model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6841169320443621"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = linear_model.LinearRegression()\n",
    "scores = cross_val_score(clf, X, y, cv=290)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train,y_Train = shuffle(X_Train,y_Train,random_state=1)\n",
    "X_Test,y_Test = shuffle(X_Test,y_Test,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.8077635570914063\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_Test,y_Test)\n",
    "print('score',clf.score(X_Test,y_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################Label Encoding##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_feature_main = ['# Chips ','# Cores Per Chip ', '# Threads Per Core', 'Processor MHz','Result','Auto Parallelization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xm = maindataset[needed_feature_main]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "ym = maindataset[[\"Baseline\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt= dataset.iloc[:,:].values\n",
    "\n",
    "Labelencoder_Xt = LabelEncoder()\n",
    "Xt[:,5] = Labelencoder_Xt.fit_transform(Xt[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test, X_Train, y_Test, y_Train = train_test_split(X, y, test_size=0.98, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_Test is (734, 5)\n",
      "The shape of y_testb is (734, 1)\n",
      "The shape of X_Train is (36014, 5)\n",
      "The shape of y_Train is (36014, 1)\n"
     ]
    }
   ],
   "source": [
    "print (\"The shape of X_Test is {}\".format(X_Test.shape))\n",
    "print (\"The shape of y_testb is {}\".format(y_Test.shape))\n",
    "print (\"The shape of X_Train is {}\".format(X_Train.shape))\n",
    "print (\"The shape of y_Train is {}\".format(y_Train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_Train # Some features\n",
    "y = y_Train # Some classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36014, 5)\n",
      "(36014, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X.fillna(0)\n",
    " print(X.shape)\n",
    " X.dropna(axis=0, how='any')\n",
    " print(X.shape)\n",
    " np.any(np.isnan(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data from Nan an finite value\n"
     ]
    }
   ],
   "source": [
    "clean_dataset(X)\n",
    "clean_dataset(y)\n",
    "clean_dataset(X_Test)\n",
    "clean_dataset(y_Test)\n",
    "print(\"cleaning data from Nan an finite value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isfinite(X))\n",
    "np.any(np.isnan(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6350795379747508"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs1 = linear_model.LinearRegression()\n",
    "scores = cross_val_score(clfs1, X, y, cv=100)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_Train,y_Train = shuffle(X_Train,y_Train,random_state=1)\n",
    "X_Test,y_Test = shuffle(X_Test,y_Test,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.8239767328876932\n"
     ]
    }
   ],
   "source": [
    "clfs1.fit(X_Test,y_Test)\n",
    "print('score',clfs1.score(X_Test,y_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################Backwar##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"maindatasetcopy.csv\")\n",
    "#x = dataset.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#needed_feature_main = ['# Chips ','# Cores Per Chip ', '# Threads Per Core', 'Processor MHz','Result','Auto Parallelization']\n",
    "needed_feature_main = ['# Chips ','# Cores Per Chip ', '# Threads Per Core', 'Processor MHz','Result']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of        # Chips   # Cores Per Chip   # Threads Per Core  Processor MHz  Result  \\\n",
       "0            16                384                   2           2200    5.86   \n",
       "1             4                 96                   1           2200    5.95   \n",
       "2             2                 44                   1           2200    6.43   \n",
       "3            16                384                   2           2200    6.66   \n",
       "4             2                 44                   1           2200    7.61   \n",
       "5             2                 56                   2           2100  291.00   \n",
       "6             2                 36                   2           2700  228.00   \n",
       "7             2                 36                   2           3000  237.00   \n",
       "8             1                  4                   2           4000    0.00   \n",
       "9             2                 20                   2           2400  109.00   \n",
       "10            2                 28                   2           2200  143.00   \n",
       "11            2                  8                   2           3600   59.30   \n",
       "12            2                 24                   2           2600  144.00   \n",
       "13            2                 12                   2           3400   88.00   \n",
       "14            2                 32                   2           2100  172.00   \n",
       "15            2                 28                   2           2600  171.00   \n",
       "16            2                 16                   2           3200  113.00   \n",
       "17            2                 24                   2           3000  158.00   \n",
       "18            2                 32                   2           2600  187.00   \n",
       "19            2                 24                   2           3200  167.00   \n",
       "20            2                 36                   2           2700  213.00   \n",
       "21            2                 36                   2           3000  221.00   \n",
       "22            2                 24                   2           3000  163.00   \n",
       "23            2                 56                   2           2100  272.00   \n",
       "24            2                 16                   2           2100   77.40   \n",
       "25            2                  8                   2           2600   47.10   \n",
       "26            4                 40                   2           2400  216.00   \n",
       "27            4                 48                   2           2300  253.00   \n",
       "28            4                 48                   2           3000  308.00   \n",
       "29            4                 48                   2           3200  328.00   \n",
       "...         ...                ...                 ...            ...     ...   \n",
       "50038         2                 12                   1           2500  323.00   \n",
       "50039         2                 12                   1           1800  272.00   \n",
       "50040         2                  4                   1           2000   64.70   \n",
       "50041         2                  4                   1           2333   69.30   \n",
       "50042         2                  4                   1           2500   71.30   \n",
       "50043         2                  4                   1           2666   73.50   \n",
       "50044         2                  4                   1           2833   75.30   \n",
       "50045         2                  4                   1           3000   77.30   \n",
       "50046         2                  4                   1           3166   79.00   \n",
       "50047         2                  4                   1           3000   88.10   \n",
       "50048         4                  6                   1           2100  252.00   \n",
       "50049         4                  6                   1           2600  276.00   \n",
       "50050         4                  6                   1           2800  285.00   \n",
       "50051         4                  4                   1           2300  186.00   \n",
       "50052         4                  4                   1           2700  210.00   \n",
       "50053         4                  4                   1           2800  215.00   \n",
       "50054         4                  4                   1           2900  218.00   \n",
       "50055         2                  4                   1           2200  123.00   \n",
       "50056         1                  4                   1           2600   70.30   \n",
       "50057         2                  4                   1           2600  136.00   \n",
       "50058         1                  6                   1           1700   67.90   \n",
       "50059         2                  6                   1           1700  132.00   \n",
       "50060         1                  6                   1           1800   71.70   \n",
       "50061         1                  6                   1           2100   80.20   \n",
       "50062         2                  6                   1           2100  155.00   \n",
       "50063         1                  6                   1           2300   85.40   \n",
       "50064         2                  6                   1           2300  165.00   \n",
       "50065         1                  6                   1           2400   87.50   \n",
       "50066         1                  6                   1           2600   90.90   \n",
       "50067         2                  6                   1           2600  175.00   \n",
       "\n",
       "      Auto Parallelization  Baseline  \n",
       "0                       No      5.31  \n",
       "1                       No      5.35  \n",
       "2                       No      5.80  \n",
       "3                       No      5.37  \n",
       "4                       No      6.16  \n",
       "5                       No    273.00  \n",
       "6                       No    216.00  \n",
       "7                       No    224.00  \n",
       "8                       No     23.50  \n",
       "9                       No    105.00  \n",
       "10                      No    136.00  \n",
       "11                      No     56.10  \n",
       "12                      No    139.00  \n",
       "13                      No     82.60  \n",
       "14                      No    164.00  \n",
       "15                      No    162.00  \n",
       "16                      No    109.00  \n",
       "17                      No    150.00  \n",
       "18                      No    178.00  \n",
       "19                      No    159.00  \n",
       "20                      No    201.00  \n",
       "21                      No    209.00  \n",
       "22                      No    154.00  \n",
       "23                      No    255.00  \n",
       "24                      No     74.20  \n",
       "25                      No     44.50  \n",
       "26                      No    206.00  \n",
       "27                      No    240.00  \n",
       "28                      No    292.00  \n",
       "29                      No    311.00  \n",
       "...                    ...       ...  \n",
       "50038                  Yes    303.00  \n",
       "50039                  Yes    256.00  \n",
       "50040                  Yes     59.20  \n",
       "50041                  Yes     63.00  \n",
       "50042                  Yes     64.70  \n",
       "50043                  Yes     66.40  \n",
       "50044                  Yes     67.90  \n",
       "50045                  Yes     69.40  \n",
       "50046                  Yes     70.80  \n",
       "50047                  Yes     78.40  \n",
       "50048                  Yes    230.00  \n",
       "50049                  Yes    253.00  \n",
       "50050                  Yes    259.00  \n",
       "50051                  Yes    167.00  \n",
       "50052                  Yes    188.00  \n",
       "50053                  Yes    193.00  \n",
       "50054                  Yes    195.00  \n",
       "50055                  Yes    111.00  \n",
       "50056                  Yes     63.30  \n",
       "50057                  Yes    124.00  \n",
       "50058                  Yes     62.60  \n",
       "50059                  Yes    123.00  \n",
       "50060                  Yes     66.30  \n",
       "50061                  Yes     73.60  \n",
       "50062                  Yes    144.00  \n",
       "50063                  Yes     78.60  \n",
       "50064                  Yes    153.00  \n",
       "50065                  Yes     80.50  \n",
       "50066                  Yes     83.50  \n",
       "50067                  Yes    162.00  \n",
       "\n",
       "[50068 rows x 7 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =dataset[needed_feature_main] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[[\"Baseline\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "xtrain, xtest, ytrain, ytest =train_test_split(x,y,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Multivariate Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_prediction= regressor.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert B Intercept\n",
    "x=np.append(arr = np.ones((50068,1)).astype(int), values = x, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Baseline</td>     <th>  R-squared:         </th>  <td>   0.019</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.019</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   988.8</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 16 May 2018</td> <th>  Prob (F-statistic):</th>  <td>6.03e-215</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:30:03</td>     <th>  Log-Likelihood:    </th> <td>-4.1544e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 50068</td>      <th>  AIC:               </th>  <td>8.309e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 50066</td>      <th>  BIC:               </th>  <td>8.309e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  290.9368</td> <td>    5.179</td> <td>   56.174</td> <td> 0.000</td> <td>  280.785</td> <td>  301.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    9.5209</td> <td>    0.303</td> <td>   31.446</td> <td> 0.000</td> <td>    8.927</td> <td>   10.114</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>109913.239</td> <th>  Durbin-Watson:     </th>    <td>   0.680</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1087689784.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>19.935</td>   <th>  Prob(JB):          </th>    <td>    0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td>723.966</td>  <th>  Cond. No.          </th>    <td>    20.4</td>   \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               Baseline   R-squared:                       0.019\n",
       "Model:                            OLS   Adj. R-squared:                  0.019\n",
       "Method:                 Least Squares   F-statistic:                     988.8\n",
       "Date:                Wed, 16 May 2018   Prob (F-statistic):          6.03e-215\n",
       "Time:                        00:30:03   Log-Likelihood:            -4.1544e+05\n",
       "No. Observations:               50068   AIC:                         8.309e+05\n",
       "Df Residuals:                   50066   BIC:                         8.309e+05\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        290.9368      5.179     56.174      0.000     280.785     301.088\n",
       "x1             9.5209      0.303     31.446      0.000       8.927      10.114\n",
       "==============================================================================\n",
       "Omnibus:                   109913.239   Durbin-Watson:                   0.680\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       1087689784.948\n",
       "Skew:                          19.935   Prob(JB):                         0.00\n",
       "Kurtosis:                     723.966   Cond. No.                         20.4\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call Ordinary Least Square\n",
    "xelimination = x[:,[0,1,2,3,4]]\n",
    "regressorOLS = sm.OLS(y, xelimination).fit()\n",
    "regressorOLS.summary()\n",
    "xelimination = x[:,[0,1,3,4]]\n",
    "regressorOLS = sm.OLS(y, xelimination).fit()\n",
    "regressorOLS.summary()\n",
    "xelimination = x[:,[0,3,4]]\n",
    "regressorOLS = sm.OLS(y, xelimination).fit()\n",
    "regressorOLS.summary()\n",
    "xelimination = x[:,[0,3]]\n",
    "regressorOLS = sm.OLS(y, xelimination).fit()\n",
    "regressorOLS.summary()\n",
    "xelimination = x[:,[0,3]]\n",
    "regressorOLS = sm.OLS(y, xelimination).fit()\n",
    "regressorOLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
