{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MPM_TF_Estimator_MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "fQT1qeT69N7G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division, print_function, absolute_import"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xDAUqevw9N_I",
        "colab_type": "code",
        "outputId": "edd27de6-c211-422a-b2b6-8f44c5164fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "cell_type": "code",
      "source": [
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-e3482ae02171>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xwXuOQftjnqQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Importing Framework"
      ]
    },
    {
      "metadata": {
        "id": "MzKi90x3jhXp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KtVu7p6XYVJz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import time Function to calculate Time"
      ]
    },
    {
      "metadata": {
        "id": "kygJGPWjYXqx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pXqWKcyiECjg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training Parameters\n",
        "learning_rate = 0.001\n",
        "num_steps = 20\n",
        "batch_size = 128\n",
        "# Network Parameters\n",
        "num_input = 784 # MNIST data input (img shape: 28*28)\n",
        "num_classes = 10 # MNIST total classes (0-9 digits)\n",
        "dropout = 0.25 # Dropout, probability to drop a unit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FaZp7Z55ECoc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create the neural network\n",
        "def conv_net(x_dict, n_classes, dropout, reuse, is_training):\n",
        "    # Define a scope for reusing the variables\n",
        "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
        "        # TF Estimator input is a dict, in case of multiple inputs\n",
        "        x = x_dict['images']\n",
        "\n",
        "        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
        "        # Reshape to match picture format [Height x Width x Channel]\n",
        "        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
        "        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
        "        \n",
        "        # Convolution Layer with 32 filters and a kernel size of 5\n",
        "        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
        "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
        "        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
        "\n",
        "        # Convolution Layer with 64 filters and a kernel size of 3 with RELU ACTIVATION\n",
        "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
        "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
        "        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
        "\n",
        "        # Flatten the data to a 1-D vector for the fully connected layer\n",
        "        fc1 = tf.contrib.layers.flatten(conv2)\n",
        "\n",
        "        # Fully connected layer \n",
        "        fc1 = tf.layers.dense(fc1, 1024)\n",
        "        # Apply Dropout (if is_training is False, dropout is not applied)\n",
        "        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
        "\n",
        "        # Output layer, class prediction\n",
        "        out = tf.layers.dense(fc1, n_classes, activation=tf.nn.softmax)\n",
        "\n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8_7OyT-LECrU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the model function (following TF Estimator Template)\n",
        "def model_fn(features, labels, mode):\n",
        "    # Build the neural network\n",
        "    # Because Dropout have different behavior at training and prediction time, we\n",
        "    # need to create 2 distinct computation graphs that still share the same weights.\n",
        "    logits_train = conv_net(features, num_classes, dropout, reuse=False,\n",
        "                            is_training=True)\n",
        "    logits_test = conv_net(features, num_classes, dropout, reuse=True,\n",
        "                           is_training=False)\n",
        "    \n",
        "    \n",
        "     # Predictions\n",
        "    pred_classes = tf.argmax(logits_test, axis=1)\n",
        "    pred_probas = tf.nn.softmax(logits_test)\n",
        "    \n",
        "     # If prediction mode, early return\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
        "      \n",
        "       # Define loss and optimizer\n",
        "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "    train_op = optimizer.minimize(loss_op,\n",
        "                                  global_step=tf.train.get_global_step())\n",
        "    \n",
        "    # Evaluate the accuracy of the model\n",
        "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
        "    \n",
        "     # TF Estimators requires to return a EstimatorSpec, that specify\n",
        "    # the different ops for training, evaluating, ...\n",
        "    estim_specs = tf.estimator.EstimatorSpec(\n",
        "        mode=mode,\n",
        "        predictions=pred_classes,\n",
        "        loss=loss_op,\n",
        "        train_op=train_op,\n",
        "        eval_metric_ops={'accuracy': acc_op})\n",
        "\n",
        "    return estim_specs\n",
        "\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7hqBhBD9YczT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start = time. time() #start time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GgXG9agOEC70",
        "colab_type": "code",
        "outputId": "59039703-fd86-4ccf-9909-2c14c6e9c433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        }
      },
      "cell_type": "code",
      "source": [
        "# Build the Estimator\n",
        "model = tf.estimator.Estimator(model_fn)\n",
        "\n",
        "# Define the input function for training\n",
        "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'images': mnist.train.images}, y=mnist.train.labels,\n",
        "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
        "# Train the Model\n",
        "model.train(input_fn, steps=num_steps)\n",
        "\n",
        "# Evaluate the Model\n",
        "# Define the input function for evaluating\n",
        "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'images': mnist.test.images}, y=mnist.test.labels,\n",
        "    batch_size=batch_size, shuffle=False)\n",
        "# Use the Estimator 'evaluate' method\n",
        "e = model.evaluate(input_fn)\n",
        "\n",
        "print(\"Testing Accuracy:\", e['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpp86tau3o\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpp86tau3o', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f118b96c940>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpp86tau3o/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.3028827, step = 1\n",
            "INFO:tensorflow:Saving checkpoints for 20 into /tmp/tmpp86tau3o/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 1.8019294.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-12-03-00:17:34\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpp86tau3o/model.ckpt-20\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-12-03-00:17:38\n",
            "INFO:tensorflow:Saving dict for global step 20: accuracy = 0.7162, global_step = 20, loss = 1.7600231\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20: /tmp/tmpp86tau3o/model.ckpt-20\n",
            "Testing Accuracy: 0.7162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uo0OsPzOYfBe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f30e6c2-ed9e-431f-d701-6f24b46b511d"
      },
      "cell_type": "code",
      "source": [
        "end = time. time()\n",
        "a =end - start\n",
        "print(\"The Time taken by model to run in seconds is %.2f seconds \"%a)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Time taken by model to run in seconds is 9.71 seconds \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}